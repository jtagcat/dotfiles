#!/bin/bash

# takes in a list of URLs, optionally with date (in csv with dumb seperator ¤)
# outputs .eml files that can be mass-imported by Thunderbird ImportExportTools NG
# use: RSS feeds only offer last n entries; getting URLs for all entries manually is usually quick and easy*, so this is a method to complete the feed listing in TB.
# * except for pagination, in which case parsehub is painfully used due to no better working alternative

# from https://unix.stackexchange.com/a/7012/389250

echo "1st: date, 2nd: url OR 1st: url"
echo "seperator is ¤"
read -p 'Directory to save files: ' filesdirectory # where are we doing stuff?
mkdir -p $filesdirectory
touch $filesdirectory/.index # get urls
$EDITOR $filesdirectory/.index
url="$(head -n1 "$filesdirectory/.index")"
title="$(wget -qO- "$url" | hq '`${/html/head/title}`')"
echo "Title of first is: $title"
read -p 'String to remove from end of title: ' removesuffix
counter=0
while IFS="¤" read date url; do
	((counter++))
	if [[ "$url" == ""  ]]; then # no date, only url (1st field)
		url="$date"
		date="Thu, 01 Jan 1970 00:00:01 +0000"
	fi
	from=$(echo "$url" | sed -e "s/[^/]*\/\/\([^@]*@\)\?\([^:/]*\).*/\2/") # get domain
	echo "From: $from" >> $filesdirectory/$counter.eml
	echo "MIME-Version: 1.0" >> $filesdirectory/$counter.eml
	fullpagetitle="$(wget -qO- "$url" | hq '`${/html/head/title}`' )"
	pagetitle="${fullpagetitle%$removesuffix}"
	echo "Subject: $pagetitle" >> $filesdirectory/$counter.eml
	echo Content-Transfer-Encoding: 8bit >> $filesdirectory/$counter.eml
	echo "Content-Base: $url" >> $filesdirectory/$counter.eml # shows up as 'website'
	echo 'Content-Type: text/html; charset=UTF-8' >> $filesdirectory/$counter.eml
	d2="$(date -R -u -d "$date")"
	echo "Date: $d2" >> $filesdirectory/$counter.eml
done < "$filesdirectory/.index"
